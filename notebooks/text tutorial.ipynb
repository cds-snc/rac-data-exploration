{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = fetch_20newsgroups(subset='train', \n",
    "                                   categories=['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med'], \n",
    "                                   shuffle=True, \n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much training data do we have (ie how many posts)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data also contains what category (newsgroup) the post came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "print(training_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 comp.graphics\n",
      "1 comp.graphics\n",
      "3 soc.religion.christian\n",
      "3 soc.religion.christian\n",
      "3 soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "for target in training_data.target[:5]:\n",
    "    print(target, training_data.target_names[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the posts into a vector of word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "training_data_counts = vectorizer.fit_transform(training_data.data)\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 35788 different words in the training data. Lots of garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '0000001200',\n",
       " '000005102000',\n",
       " '0001',\n",
       " '000100255pixel',\n",
       " '00014',\n",
       " '000406',\n",
       " '0007']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the word counts for the first post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x35788 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 73 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 230)\t1\n",
      "  (0, 12541)\t1\n",
      "  (0, 3166)\t1\n",
      "  (0, 14085)\t1\n",
      "  (0, 20459)\t1\n",
      "  (0, 35416)\t1\n",
      "  (0, 3062)\t1\n",
      "  (0, 2326)\t2\n",
      "  (0, 177)\t2\n",
      "  (0, 31915)\t1\n",
      "  (0, 33572)\t1\n",
      "  (0, 9338)\t1\n",
      "  (0, 26175)\t1\n",
      "  (0, 4378)\t1\n",
      "  (0, 17556)\t1\n",
      "  (0, 32135)\t1\n",
      "  (0, 15837)\t1\n",
      "  (0, 9932)\t1\n",
      "  (0, 32270)\t1\n",
      "  (0, 18474)\t1\n",
      "  (0, 27836)\t1\n",
      "  (0, 5195)\t1\n",
      "  (0, 12833)\t2\n",
      "  (0, 25337)\t1\n",
      "  (0, 25361)\t1\n",
      "  :\t:\n",
      "  (0, 5201)\t1\n",
      "  (0, 12051)\t1\n",
      "  (0, 587)\t1\n",
      "  (0, 20253)\t1\n",
      "  (0, 33597)\t2\n",
      "  (0, 32142)\t5\n",
      "  (0, 23915)\t1\n",
      "  (0, 16082)\t1\n",
      "  (0, 16881)\t1\n",
      "  (0, 25663)\t1\n",
      "  (0, 23122)\t1\n",
      "  (0, 17302)\t2\n",
      "  (0, 19780)\t2\n",
      "  (0, 16916)\t2\n",
      "  (0, 32493)\t4\n",
      "  (0, 17366)\t1\n",
      "  (0, 9805)\t2\n",
      "  (0, 31077)\t1\n",
      "  (0, 9031)\t3\n",
      "  (0, 21661)\t3\n",
      "  (0, 33256)\t2\n",
      "  (0, 4017)\t2\n",
      "  (0, 8696)\t4\n",
      "  (0, 29022)\t1\n",
      "  (0, 14887)\t1\n"
     ]
    }
   ],
   "source": [
    "print(training_data_counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word #8696 occurred 4 times. What word is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[8696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['citizen',\n",
       " 'citizens',\n",
       " 'citizenship',\n",
       " 'citr',\n",
       " 'citrate',\n",
       " 'citrus',\n",
       " 'city',\n",
       " 'city_________________________________________________',\n",
       " 'civic',\n",
       " 'civil']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[8690:8700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are not stemming words - we have both `citizen` and `citizens`. We also have `city` with a bunch of underscores after it (?) So basically, our data could really use some cleaning up (that we're not going to bother with today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a document is really long it will in general have higher word counts, so it might seem to be more relavant than a shorter doccument which uses key words relatively more often. To counter this we usually normalize the counts by the length of the document in some fashion.\n",
    "\n",
    "Also, if a word occurs in most of the documents, it probably doesn't have much information value. So we want to reduce its score.\n",
    "\n",
    "A common way to do both of these is to calculate the Term Frequency Inverse Document Frequency (TFIDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "training_counts_tfidf = tfidf_transformer.fit_transform(training_data_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 35416)\t0.1348710554299733\n",
      "  (0, 35312)\t0.0312703097833574\n",
      "  (0, 34775)\t0.034481472140846715\n",
      "  (0, 34755)\t0.043341654399042764\n",
      "  (0, 33915)\t0.0999409997803694\n",
      "  (0, 33597)\t0.06567578043186388\n",
      "  (0, 33572)\t0.09313007554599557\n",
      "  (0, 33256)\t0.11819702490105698\n",
      "  (0, 32493)\t0.07283773941616518\n",
      "  (0, 32391)\t0.12806013119559947\n",
      "  (0, 32270)\t0.023871142738151236\n",
      "  (0, 32142)\t0.08865416253721688\n",
      "  (0, 32135)\t0.04910237380446671\n",
      "  (0, 32116)\t0.10218403421141944\n",
      "  (0, 31915)\t0.08631915131162177\n",
      "  (0, 31077)\t0.016797806021219684\n",
      "  (0, 30623)\t0.0686611288079694\n",
      "  (0, 29022)\t0.1348710554299733\n",
      "  (0, 28619)\t0.047271576160535234\n",
      "  (0, 27836)\t0.06899050810672397\n",
      "  (0, 26175)\t0.08497460943470851\n",
      "  (0, 25663)\t0.034290706362898604\n",
      "  (0, 25361)\t0.11947938145690981\n",
      "  (0, 25337)\t0.04935883383975408\n",
      "  (0, 24677)\t0.09796250319482307\n",
      "  :\t:\n",
      "  (0, 14676)\t0.07691883385947053\n",
      "  (0, 14281)\t0.13635772403701527\n",
      "  (0, 14085)\t0.06666452137859726\n",
      "  (0, 12833)\t0.125601499991304\n",
      "  (0, 12541)\t0.1348710554299733\n",
      "  (0, 12051)\t0.037793189755988436\n",
      "  (0, 12014)\t0.031042954435189937\n",
      "  (0, 9932)\t0.06350565647195339\n",
      "  (0, 9805)\t0.21567205914741705\n",
      "  (0, 9801)\t0.07830787326179856\n",
      "  (0, 9338)\t0.049671845493333165\n",
      "  (0, 9031)\t0.3841803935867984\n",
      "  (0, 8696)\t0.314400065528974\n",
      "  (0, 5285)\t0.08413454409085573\n",
      "  (0, 5201)\t0.04316199700711876\n",
      "  (0, 5195)\t0.0310951485922154\n",
      "  (0, 4808)\t0.03900412426100995\n",
      "  (0, 4378)\t0.0686611288079694\n",
      "  (0, 4017)\t0.12491817585060791\n",
      "  (0, 3166)\t0.1348710554299733\n",
      "  (0, 3062)\t0.10783602957370853\n",
      "  (0, 2326)\t0.24645540709354397\n",
      "  (0, 587)\t0.05966162012870271\n",
      "  (0, 230)\t0.1348710554299733\n",
      "  (0, 177)\t0.25612026239119895\n"
     ]
    }
   ],
   "source": [
    "print(training_counts_tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(training_counts_tfidf, training_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'doctors are cool' => sci.med\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "testing_data = ['doctors are cool', 'OpenGL on the GPU is fast']\n",
    "testing_counts = vectorizer.transform(testing_data)\n",
    "testing_counts_tfidf = tfidf_transformer.transform(testing_counts)\n",
    "\n",
    "predicted = nb_classifier.predict(testing_counts_tfidf)\n",
    "\n",
    "for doc, category in zip(testing_data, predicted):\n",
    "    print('%r => %s' % (doc, training_data.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can string the vectorizer, TFIDF, and classifier together in an sklearn Pipeline, to create a new classifier that works directly with the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nb_classifier = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_classifier.fit(training_data.data, training_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on a real test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348868175765646"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "testing_data = fetch_20newsgroups(subset='test', categories=training_data.target_names, shuffle=True, random_state=42)\n",
    "testing_data_predictions = nb_classifier.predict(testing_data.data\\\n",
    "                                                )\n",
    "np.mean(testing_data_predictions == testing_data.target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we guess right 83% of the time. Not terrible! Let's get some more metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.60      0.74       319\n",
      "         comp.graphics       0.96      0.89      0.92       389\n",
      "               sci.med       0.97      0.81      0.88       396\n",
      "soc.religion.christian       0.65      0.99      0.78       398\n",
      "\n",
      "             micro avg       0.83      0.83      0.83      1502\n",
      "             macro avg       0.89      0.82      0.83      1502\n",
      "          weighted avg       0.88      0.83      0.84      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(testing_data.target, \n",
    "                                    testing_data_predictions, \n",
    "                                    target_names=training_data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\text{precision of category} & = \\frac {\\text {number from that category guessed correctly}} \n",
    "                                        {\\text{total number from that category}} \\\\\n",
    "                             & = \\text {what proportion of that category did we guess right} \\\\\n",
    "                             \\\\\n",
    "\\text{recall of category} &= \\frac {\\text {number from that category guessed correctly}} \n",
    "                                        {\\text{number we thought were from that category}} \\\\\n",
    "                          &= \\text {of the ones we thought were that category, what proportion were we correct about}                                  \n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want the precision and precall to both be 1. \n",
    "\n",
    "In this case, alt.atheism has a precision of 0.97, so 97% of the alt.atheism posts got correctly labelled.\n",
    "\n",
    "On the other hand, the recall is 0.6, which means that when we say a post in from alt.atheism, we're right 60% of the time.\n",
    "\n",
    "Note that soc.religion.christianity has the opposite problem. It would appear that we are classifying too many religion-related posts as alt.atheism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confusion matrix** shows us how many things got classified as other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192,   2,   6, 119],\n",
       "       [  2, 347,   4,  36],\n",
       "       [  2,  11, 322,  61],\n",
       "       [  2,   2,   1, 393]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(testing_data.target, testing_data_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Support vector machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephen/.local/share/virtualenvs/racc-data-exploration-_ecVW4H5/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9127829560585885"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.87       319\n",
      "         comp.graphics       0.88      0.97      0.92       389\n",
      "               sci.med       0.94      0.90      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "             micro avg       0.91      0.91      0.91      1502\n",
      "             macro avg       0.92      0.91      0.91      1502\n",
      "          weighted avg       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258,  11,  15,  35],\n",
       "       [  4, 379,   3,   3],\n",
       "       [  5,  33, 355,   3],\n",
       "       [  5,  10,   4, 379]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
