{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = fetch_20newsgroups(subset='train', \n",
    "                                   categories=['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med'], \n",
    "                                   shuffle=True, \n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much training data do we have (ie how many posts)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data also contains what category (newsgroup) the post came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "print(training_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 comp.graphics\n",
      "1 comp.graphics\n",
      "3 soc.religion.christian\n",
      "3 soc.religion.christian\n",
      "3 soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "for target in training_data.target[:5]:\n",
    "    print(target, training_data.target_names[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the posts into a vector of word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "training_data_counts = vectorizer.fit_transform(training_data.data)\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 35788 different words in the training data. Lots of garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '0000001200',\n",
       " '000005102000',\n",
       " '0001',\n",
       " '000100255pixel',\n",
       " '00014',\n",
       " '000406',\n",
       " '0007']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the word counts for the first post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x35788 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 73 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 230)\t1\n",
      "  (0, 12541)\t1\n",
      "  (0, 3166)\t1\n",
      "  (0, 14085)\t1\n",
      "  (0, 20459)\t1\n",
      "  (0, 35416)\t1\n",
      "  (0, 3062)\t1\n",
      "  (0, 2326)\t2\n",
      "  (0, 177)\t2\n",
      "  (0, 31915)\t1\n",
      "  (0, 33572)\t1\n",
      "  (0, 9338)\t1\n",
      "  (0, 26175)\t1\n",
      "  (0, 4378)\t1\n",
      "  (0, 17556)\t1\n",
      "  (0, 32135)\t1\n",
      "  (0, 15837)\t1\n",
      "  (0, 9932)\t1\n",
      "  (0, 32270)\t1\n",
      "  (0, 18474)\t1\n",
      "  (0, 27836)\t1\n",
      "  (0, 5195)\t1\n",
      "  (0, 12833)\t2\n",
      "  (0, 25337)\t1\n",
      "  (0, 25361)\t1\n",
      "  :\t:\n",
      "  (0, 5201)\t1\n",
      "  (0, 12051)\t1\n",
      "  (0, 587)\t1\n",
      "  (0, 20253)\t1\n",
      "  (0, 33597)\t2\n",
      "  (0, 32142)\t5\n",
      "  (0, 23915)\t1\n",
      "  (0, 16082)\t1\n",
      "  (0, 16881)\t1\n",
      "  (0, 25663)\t1\n",
      "  (0, 23122)\t1\n",
      "  (0, 17302)\t2\n",
      "  (0, 19780)\t2\n",
      "  (0, 16916)\t2\n",
      "  (0, 32493)\t4\n",
      "  (0, 17366)\t1\n",
      "  (0, 9805)\t2\n",
      "  (0, 31077)\t1\n",
      "  (0, 9031)\t3\n",
      "  (0, 21661)\t3\n",
      "  (0, 33256)\t2\n",
      "  (0, 4017)\t2\n",
      "  (0, 8696)\t4\n",
      "  (0, 29022)\t1\n",
      "  (0, 14887)\t1\n"
     ]
    }
   ],
   "source": [
    "print(training_data_counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word #8696 occurred 4 times. What word is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[8696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['citizen',\n",
       " 'citizens',\n",
       " 'citizenship',\n",
       " 'citr',\n",
       " 'citrate',\n",
       " 'citrus',\n",
       " 'city',\n",
       " 'city_________________________________________________',\n",
       " 'civic',\n",
       " 'civil']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[8690:8700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are not stemming words - we have both `citizen` and `citizens`. We also have `city` with a bunch of underscores after it (?) So basically, our data could really use some cleaning up (that we're not going to bother with today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a document is really long it will in general have higher word counts, so it might seem to be more relavant than a shorter doccument which uses key words relatively more often. To counter this we usually normalize the counts by the length of the document in some fashion.\n",
    "\n",
    "Also, if a word occurs in most of the documents, it probably doesn't have much information value. So we want to reduce its score.\n",
    "\n",
    "A common way to do both of these is to calculate the Term Frequency Inverse Document Frequency (TFIDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "training_counts_tfidf = tfidf_transformer.fit_transform(training_data_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 35416)\t0.1348710554299733\n",
      "  (0, 35312)\t0.0312703097833574\n",
      "  (0, 34775)\t0.034481472140846715\n",
      "  (0, 34755)\t0.043341654399042764\n",
      "  (0, 33915)\t0.0999409997803694\n",
      "  (0, 33597)\t0.06567578043186388\n",
      "  (0, 33572)\t0.09313007554599557\n",
      "  (0, 33256)\t0.11819702490105698\n",
      "  (0, 32493)\t0.07283773941616518\n",
      "  (0, 32391)\t0.12806013119559947\n",
      "  (0, 32270)\t0.023871142738151236\n",
      "  (0, 32142)\t0.08865416253721688\n",
      "  (0, 32135)\t0.04910237380446671\n",
      "  (0, 32116)\t0.10218403421141944\n",
      "  (0, 31915)\t0.08631915131162177\n",
      "  (0, 31077)\t0.016797806021219684\n",
      "  (0, 30623)\t0.0686611288079694\n",
      "  (0, 29022)\t0.1348710554299733\n",
      "  (0, 28619)\t0.047271576160535234\n",
      "  (0, 27836)\t0.06899050810672397\n",
      "  (0, 26175)\t0.08497460943470851\n",
      "  (0, 25663)\t0.034290706362898604\n",
      "  (0, 25361)\t0.11947938145690981\n",
      "  (0, 25337)\t0.04935883383975408\n",
      "  (0, 24677)\t0.09796250319482307\n",
      "  :\t:\n",
      "  (0, 14676)\t0.07691883385947053\n",
      "  (0, 14281)\t0.13635772403701527\n",
      "  (0, 14085)\t0.06666452137859726\n",
      "  (0, 12833)\t0.125601499991304\n",
      "  (0, 12541)\t0.1348710554299733\n",
      "  (0, 12051)\t0.037793189755988436\n",
      "  (0, 12014)\t0.031042954435189937\n",
      "  (0, 9932)\t0.06350565647195339\n",
      "  (0, 9805)\t0.21567205914741705\n",
      "  (0, 9801)\t0.07830787326179856\n",
      "  (0, 9338)\t0.049671845493333165\n",
      "  (0, 9031)\t0.3841803935867984\n",
      "  (0, 8696)\t0.314400065528974\n",
      "  (0, 5285)\t0.08413454409085573\n",
      "  (0, 5201)\t0.04316199700711876\n",
      "  (0, 5195)\t0.0310951485922154\n",
      "  (0, 4808)\t0.03900412426100995\n",
      "  (0, 4378)\t0.0686611288079694\n",
      "  (0, 4017)\t0.12491817585060791\n",
      "  (0, 3166)\t0.1348710554299733\n",
      "  (0, 3062)\t0.10783602957370853\n",
      "  (0, 2326)\t0.24645540709354397\n",
      "  (0, 587)\t0.05966162012870271\n",
      "  (0, 230)\t0.1348710554299733\n",
      "  (0, 177)\t0.25612026239119895\n"
     ]
    }
   ],
   "source": [
    "print(training_counts_tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(training_counts_tfidf, training_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'doctors are cool' => sci.med\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "testing_data = ['doctors are cool', 'OpenGL on the GPU is fast']\n",
    "testing_counts = vectorizer.transform(testing_data)\n",
    "testing_counts_tfidf = tfidf_transformer.transform(testing_counts)\n",
    "\n",
    "predicted = nb_classifier.predict(testing_counts_tfidf)\n",
    "\n",
    "for doc, category in zip(testing_data, predicted):\n",
    "    print('%r => %s' % (doc, training_data.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can string the vectorizer, TFIDF, and classifier together in an sklearn Pipeline, to create a new classifier that works directly with the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nb_classifier = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_classifier.fit(training_data.data, training_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on a real test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348868175765646"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "testing_data = fetch_20newsgroups(subset='test', categories=training_data.target_names, shuffle=True, random_state=42)\n",
    "testing_data_predictions = nb_classifier.predict(testing_data.data\\\n",
    "                                                )\n",
    "np.mean(testing_data_predictions == testing_data.target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we guess right 83% of the time. Not terrible! Let's get some more metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.60      0.74       319\n",
      "         comp.graphics       0.96      0.89      0.92       389\n",
      "               sci.med       0.97      0.81      0.88       396\n",
      "soc.religion.christian       0.65      0.99      0.78       398\n",
      "\n",
      "             micro avg       0.83      0.83      0.83      1502\n",
      "             macro avg       0.89      0.82      0.83      1502\n",
      "          weighted avg       0.88      0.83      0.84      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(testing_data.target, \n",
    "                                    testing_data_predictions, \n",
    "                                    target_names=training_data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\text{precision of category} & = \\frac {\\text {number from that category guessed correctly}} \n",
    "                                        {\\text{total number from that category}} \\\\\n",
    "                             & = \\text {what proportion of that category did we guess right} \\\\\n",
    "                             \\\\\n",
    "\\text{recall of category} &= \\frac {\\text {number from that category guessed correctly}} \n",
    "                                        {\\text{number we thought were from that category}} \\\\\n",
    "                          &= \\text {of the ones we thought were that category, what proportion were we correct about}                                  \n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want the precision and precall to both be 1. \n",
    "\n",
    "In this case, alt.atheism has a precision of 0.97, so 97% of the alt.atheism posts got correctly labelled.\n",
    "\n",
    "On the other hand, the recall is 0.6, which means that when we say a post in from alt.atheism, we're right 60% of the time.\n",
    "\n",
    "Note that soc.religion.christianity has the opposite problem. It would appear that we are classifying too many religion-related posts as alt.atheism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confusion matrix** shows us how many things got classified as other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.med</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">predicted</th>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>2</td>\n",
       "      <td>347</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>322</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      actual                        \\\n",
       "                                 alt.atheism comp.graphics sci.med   \n",
       "predicted alt.atheism                    192             2       6   \n",
       "          comp.graphics                    2           347       4   \n",
       "          sci.med                          2            11     322   \n",
       "          soc.religion.christian           2             2       1   \n",
       "\n",
       "                                                         \n",
       "                                 soc.religion.christian  \n",
       "predicted alt.atheism                               119  \n",
       "          comp.graphics                              36  \n",
       "          sci.med                                    61  \n",
       "          soc.religion.christian                    393  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "row_index = pd.MultiIndex.from_tuples([('predicted', x) for x in training_data.target_names])\n",
    "col_index = pd.MultiIndex.from_tuples([('actual', x) for x in training_data.target_names])\n",
    "confusion_matrix = metrics.confusion_matrix(testing_data.target, testing_data_predictions)\n",
    "\n",
    "pd.DataFrame(confusion_matrix, index=row_index, columns=col_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that of the posts predicted to be alt.atheism, almost a third were actually soc.religion.christian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better data munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can improve the data a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "stem_vectorizer = CountVectorizer(analyzer=stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=<function stemmed_words at 0x123a0b158>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=Non...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier = Pipeline([\n",
    "    ('vect', stem_vectorizer),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_classifier.fit(training_data.data, training_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288948069241012"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data_predictions = nb_classifier.predict(testing_data.data)\n",
    "np.mean(testing_data_predictions == testing_data.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.med</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">predicted</th>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>2</td>\n",
       "      <td>348</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>322</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      actual                        \\\n",
       "                                 alt.atheism comp.graphics sci.med   \n",
       "predicted alt.atheism                    183             2       7   \n",
       "          comp.graphics                    2           348       7   \n",
       "          sci.med                          3            10     322   \n",
       "          soc.religion.christian           2             2       2   \n",
       "\n",
       "                                                         \n",
       "                                 soc.religion.christian  \n",
       "predicted alt.atheism                               127  \n",
       "          comp.graphics                              32  \n",
       "          sci.med                                    61  \n",
       "          soc.religion.christian                    392  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_index = pd.MultiIndex.from_tuples([('predicted', x) for x in training_data.target_names])\n",
    "col_index = pd.MultiIndex.from_tuples([('actual', x) for x in training_data.target_names])\n",
    "confusion_matrix = metrics.confusion_matrix(testing_data.target, testing_data_predictions)\n",
    "\n",
    "pd.DataFrame(confusion_matrix, index=row_index, columns=col_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly the results are worse than with the non-stemmed words :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Use a better classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a slightly better classifier, a support vector machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9121171770972037"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=10, tol=0.01)),\n",
    "])\n",
    "\n",
    "svm_clf.fit(training_data.data, training_data.target)  \n",
    "\n",
    "testing_data_predictions = svm_clf.predict(testing_data.data)\n",
    "np.mean(testing_data_predictions == testing_data.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.med</th>\n",
       "      <th>soc.religion.christian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">predicted</th>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>261</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>4</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med</th>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      actual                        \\\n",
       "                                 alt.atheism comp.graphics sci.med   \n",
       "predicted alt.atheism                    261            10      12   \n",
       "          comp.graphics                    4           380       2   \n",
       "          sci.med                          7            36     349   \n",
       "          soc.religion.christian           5            11       2   \n",
       "\n",
       "                                                         \n",
       "                                 soc.religion.christian  \n",
       "predicted alt.atheism                                36  \n",
       "          comp.graphics                               3  \n",
       "          sci.med                                     4  \n",
       "          soc.religion.christian                    380  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_index = pd.MultiIndex.from_tuples([('predicted', x) for x in training_data.target_names])\n",
    "col_index = pd.MultiIndex.from_tuples([('actual', x) for x in training_data.target_names])\n",
    "confusion_matrix = metrics.confusion_matrix(testing_data.target, testing_data_predictions)\n",
    "\n",
    "pd.DataFrame(confusion_matrix, index=row_index, columns=col_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we are not over-predicting alt.atheism nearly as badly as we were using Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.94      0.82      0.88       319\n",
      "         comp.graphics       0.87      0.98      0.92       389\n",
      "               sci.med       0.96      0.88      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "             micro avg       0.91      0.91      0.91      1502\n",
      "             macro avg       0.92      0.91      0.91      1502\n",
      "          weighted avg       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(testing_data.target, \n",
    "                                    testing_data_predictions, \n",
    "                                    target_names=training_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
